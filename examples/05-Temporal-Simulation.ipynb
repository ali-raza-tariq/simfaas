{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Simulation\n",
    "\n",
    "Assuming stationary processes, we used the previously demonstrated (check other examples)\n",
    "average QoS metrics over time by simulating for a very large `max_time`. Here, our goal is to find\n",
    "temporal characteristics by calculating sample averages (with limited time executation).\n",
    "To do so, we need to provide the function instances in the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from pacssim.SimProcess import ExpSimProcess\n",
    "from pacssim.FunctionInstance import FunctionInstance\n",
    "from pacssim.ServerlessTemporalSimulator import ServerlessTemporalSimulator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "cold_service_rate = 1/2.163\n",
    "warm_service_rate = 1/2.016\n",
    "expiration_threshold = 600\n",
    "\n",
    "arrival_rate = 0.9\n",
    "max_time = 3600\n",
    "\n",
    "# number of simulations samples produced\n",
    "num_sim = 1000\n",
    "\n",
    "running_function_count = 3\n",
    "idle_function_count = 5\n",
    "\n",
    "cold_service_process = ExpSimProcess(rate=cold_service_rate)\n",
    "warm_service_process = ExpSimProcess(rate=warm_service_rate)\n",
    "\n",
    "def generate_trace():\n",
    "    idle_functions = []\n",
    "    for _ in range(idle_function_count):\n",
    "        f = FunctionInstance(0,\n",
    "                                cold_service_process,\n",
    "                                warm_service_process,\n",
    "                                expiration_threshold\n",
    "                                )\n",
    "\n",
    "        f.state = 'IDLE'\n",
    "        f.is_cold = False\n",
    "        # when will it be destroyed if no requests\n",
    "        f.next_termination = 300\n",
    "        # so that they would be less likely to be chosen by scheduler\n",
    "        f.creation_time = 0.01\n",
    "        idle_functions.append(f)\n",
    "\n",
    "    running_functions = []\n",
    "    for _ in range(running_function_count):\n",
    "        f = FunctionInstance(0,\n",
    "                                cold_service_process,\n",
    "                                warm_service_process,\n",
    "                                expiration_threshold\n",
    "                                )\n",
    "\n",
    "        f.state = 'IDLE'\n",
    "        f.is_cold = False\n",
    "        # transition it into running mode\n",
    "        f.arrival_transition(0)\n",
    "\n",
    "        running_functions.append(f)\n",
    "\n",
    "    sim = ServerlessTemporalSimulator(running_functions, idle_functions, arrival_rate=arrival_rate, warm_service_rate=warm_service_rate, cold_service_rate=cold_service_rate,\n",
    "                                        expiration_threshold=expiration_threshold, max_time=max_time)\n",
    "    sim.generate_trace(debug_print=False, progress=False)\n",
    "    return sim.get_cold_start_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]The probability of cold start request in the next 3600s is: 0.00116955\n\n"
    }
   ],
   "source": [
    "traces = [generate_trace() for _ in tqdm(range(num_sim))]\n",
    "p_cold = np.mean(traces)\n",
    "print(f\"The probability of cold start request in the next {max_time}s is: {p_cold:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute Workload using ZeroMQ\n",
    "\n",
    "In this section, we will be using ZeroMQ to distribute workload of generating temporal traces\n",
    "among distributed workers. Doing so, gives us the ability to get a much higher throughput of\n",
    "simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "from threading import Thread\n",
    "import struct\n",
    "\n",
    "import zmq\n",
    "\n",
    "port = \"5556\"\n",
    "\n",
    "\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.DEALER)\n",
    "socket.setsockopt(zmq.IDENTITY, b'master')\n",
    "socket_addr = \"tcp://127.0.0.1:%s\" % port\n",
    "socket.bind(socket_addr)\n",
    "\n",
    "poller = zmq.Poller()\n",
    "poller.register(socket, zmq.POLLIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting thread: worker-0\nStarting thread: worker-1\nStarting thread: worker-2\nStarting thread: worker-3\nStarting thread: worker-4\nStarting thread: worker-5\nStarting thread: worker-6\nStarting thread: worker-7\nStarting thread: worker-8\nStarting thread: worker-9\nStarting thread: worker-10\nStarting thread: worker-11\nStarting thread: worker-12\nStarting thread: worker-13\nStarting thread: worker-14\nStarting thread: worker-15\nStarting thread: worker-16\nStarting thread: worker-17\nStarting thread: worker-18\nStarting thread: worker-19\nStarting thread: worker-20\nStarting thread: worker-21\nStarting thread: worker-22\nStarting thread: worker-23\nStarting thread: worker-24\nStarting thread: worker-25\nStarting thread: worker-26\nStarting thread: worker-27\nStarting thread: worker-28\nStarting thread: worker-29\nStarting thread: worker-30\nStarting thread: worker-31\n"
    }
   ],
   "source": [
    "worker_count = 32\n",
    "\n",
    "stop_signal = False\n",
    "def worker(context=None, name=\"worker\"):\n",
    "    context = context or zmq.Context.instance()\n",
    "    worker = context.socket(zmq.ROUTER)\n",
    "    worker.connect(socket_addr)\n",
    "\n",
    "    print(f\"Starting thread: {name}\")\n",
    "\n",
    "    poller = zmq.Poller()\n",
    "    poller.register(worker, zmq.POLLIN)\n",
    "    while not stop_signal:\n",
    "        socks = dict(poller.poll(timeout=1000))\n",
    "\n",
    "        if worker in socks and socks[worker] == zmq.POLLIN:\n",
    "            ident, message = worker.recv_multipart()\n",
    "            \n",
    "            # calculate trace\n",
    "            msg = struct.pack(\"d\", generate_trace())\n",
    "            \n",
    "            worker.send_multipart([ident, msg])\n",
    "\n",
    "# t = Thread(target=worker)\n",
    "# t.start()\n",
    "\n",
    "worker_names = [f\"worker-{i}\" for i in range(worker_count)]\n",
    "worker_funcs = [lambda context=None,name=n: worker(context=context, name=name) for n in worker_names]\n",
    "worker_threads = [Thread(target=f) for f in worker_funcs]\n",
    "_ = [t.start() for t in worker_threads]\n",
    "\n",
    "# wait for threads to stabilize\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sims = 1000\n",
    "\n",
    "def sender(num):\n",
    "    # send the tasks\n",
    "    for _ in range(num):\n",
    "        request = b\"HI\"\n",
    "        socket.send(request)\n",
    "\n",
    "st = Thread(target=sender, args=(total_sims,))\n",
    "st.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1000/1000 [04:30<00:00,  3.69it/s]\n"
    }
   ],
   "source": [
    "pbar = tqdm(total=int(total_sims))\n",
    "\n",
    "received_sims = 0\n",
    "results = []\n",
    "# receive the results\n",
    "while received_sims < total_sims:\n",
    "    socks = dict(poller.poll(timeout=30000))\n",
    "    if socks == {}:\n",
    "        print(\"Timeout!\")\n",
    "        break\n",
    "\n",
    "    if socket in socks and socks[socket] == zmq.POLLIN:\n",
    "        # print(\"Message from socket: %s\" % struct.unpack(\"d\", socket.recv()))\n",
    "        results.append(struct.unpack(\"d\", socket.recv()))\n",
    "        received_sims += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The probability of cold start request in the next 3600s is: nan\n"
    }
   ],
   "source": [
    "p_cold = np.mean(results)\n",
    "print(f\"The probability of cold start request in the next {max_time}s is: {p_cold:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "stop_signal = True\n",
    "[t.join() for t in worker_threads]\n",
    "st.is_alive()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitsimenvconda6f26dd105ce74d34af4003741cf4fdff",
   "display_name": "Python 3.6.10 64-bit ('simenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}